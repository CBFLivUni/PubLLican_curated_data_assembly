print("Processed pmids:")
print(paste0(j,"/",length(pmids_list)))
pmid <- pmids_list[j]
pmid_curated_data <- genes_curated_df_clean[genes_curated_df_clean$PMID == pmid, ]
pmid_test_gene_data <- genes_test_df[genes_test_df$PMID == pmid, ]
# Extract unique gene-symbol and species pairs for the current PMID from the test dataset
ai_gene_species_pairs <- pmid_test_gene_data %>%
select(gene_symbol_clean, species_latin_name) %>%
distinct()
# Iterate through each AI gene-symbol for the current PMID
for (i in seq_len(nrow(ai_gene_species_pairs))) {
# i = 1
# print("i:")
# print(i) # for troubleshooting
ai_gene_symbol <- ai_gene_species_pairs$gene_symbol_clean[i]
if (length(ai_gene_symbol) > 100) {
print("Too many genes annotated by AI. Leaving this PMID for later.")
pmids_to_process_again <- c(pmids_to_process_again, pmid)
next
}
ai_species <- ai_gene_species_pairs$species_latin_name[i]
# Iterate through each column to check in the curated dataset
for (col in cols_to_check) {
# print("col:")
# print(col) # for troubleshooting
# col <- "Synonym"
# Perform forward and reverse matching (vectorised using only valid patterns)
valid_patterns <- pmid_curated_data[[col]][!is.na(pmid_curated_data[[col]]) & pmid_curated_data[[col]] != ""]
# check if any valid patterns remain, if nor proceed on to the next column
if (length(valid_patterns) == 0) {
next  # Skip to the next column if no valid patterns
} else if (length(valid_patterns) >= 100) {
print("Too many genes provided by curator. Leaving this PMID for later.")
pmids_to_process_again <- c(pmids_to_process_again, pmid)
next
}
# Perform regex matching (forward) with valid patterns
sym_to_col_match <- sapply(valid_patterns, function(pattern) {
safe_grepl(ai_gene_symbol, pattern, ignore.case = TRUE)
})
# Perform reverse matching only on valid patterns
reverse_match <- sapply(valid_patterns, function(pattern) {
safe_grepl(pattern, ai_gene_symbol, ignore.case = TRUE)
})
# Combine results
match_results <- sym_to_col_match | reverse_match
# If a match is found, record the species and other details
if (any(match_results, na.rm = TRUE)) {
matching_rows <- which(match_results)
for (row in matching_rows) {
# row <- 1
# print("row:")
# print(row) # for troubleshooting
gene_match_hits <- rbind(gene_match_hits, data.frame(
PMID = pmid,
ai_species = ai_species,
curator_species = pmid_curated_data$Species[row],
ai_symbol = ai_gene_symbol,
curator_symbol = pmid_curated_data[[col]][row],
matching_column = col,
gene_match_found = TRUE,
stringsAsFactors = FALSE
))
}
} else {
gene_match_hits <- rbind(gene_match_hits, data.frame(
PMID = pmid,
ai_species = ai_species,
curator_species = "No match for gene",
ai_symbol = ai_gene_symbol,
curator_symbol = "No match",
matching_column = "No match",
gene_match_found = FALSE,
stringsAsFactors = FALSE
))
}
}
}
}
View(gene_match_hits)
ai_genes_with_matches <- gene_match_hits[gene_match_hits$gene_match_found == TRUE, ]
View(ai_genes_with_matches)
names(ai_genes_with_matches)
ai_genes_with_collapsed_matches <- ai_genes_with_matches %>%
group_by(PMID, ai_species, curator_species, ai_symbol, curator_symbol) %>%
summarize(
matching_column = paste(unique(matching_column), collapse = ";"),
.groups = "drop"  # Ungroup after summarization
)
View(ai_genes_with_collapsed_matches)
head(genes_curated_df_clean)
head(ai_genes_with_collapsed_matches)
head(genes_curated_df_clean)
# Step 1: Count total curated genes per PMID
curated_gene_count <- genes_curated_df_clean %>%
group_by(PMID) %>%
summarize(total_curated_genes = n_distinct(DB_Symbol, Synonym, Name, DB_ID), .groups = "drop")
# Step 2: Count AI-matched genes per PMID
ai_gene_match_count <- ai_genes_with_collapsed_matches %>%
group_by(PMID) %>%
summarize(matched_genes = n_distinct(ai_symbol), .groups = "drop")
# Step 3: Join and calculate recall
recall_df <- curated_gene_count %>%
left_join(ai_gene_match_count, by = "PMID") %>%
mutate(
matched_genes = ifelse(is.na(matched_genes), 0, matched_genes), # Handle PMIDs with no matches
recall = matched_genes / total_curated_genes
) %>%
arrange(desc(recall))
View(recall_df)
View(ai_gene_match_count)
View(curated_gene_count)
View(ai_genes_with_collapsed_matches)
View(ai_genes_with_collapsed_matches)
# Step 1: Count total curated genes per PMID
curated_gene_count <- genes_curated_df_clean %>%
group_by(PMID) %>%
summarize(total_curated_genes = n(), .groups = "drop")  # Number of rows per PMID
View(curated_gene_count)
# Step 2: Count AI-matched genes per PMID
ai_gene_match_count <- ai_genes_with_collapsed_matches %>%
group_by(PMID) %>%
summarize(matched_genes = n_distinct(ai_symbol), .groups = "drop")
# Step 3: Join and calculate recall
recall_df <- curated_gene_count %>%
left_join(ai_gene_match_count, by = "PMID") %>%
mutate(
matched_genes = ifelse(is.na(matched_genes), 0, matched_genes), # Handle PMIDs with no matches
recall = matched_genes / total_curated_genes
) %>%
arrange(desc(recall))
View(recall_df)
# Step 3: Join and calculate recall
recall_df <- curated_gene_count %>%
left_join(ai_gene_match_count, by = "PMID")
View(recall_df)
# Step 3: Join and calculate recall
recall_df <- curated_gene_count %>%
left_join(ai_gene_match_count, by = "PMID") %>%
mutate(
matched_genes = ifelse(is.na(matched_genes), 0, matched_genes), # Handle PMIDs with no matches
)
View(recall_df)
recall_df$recall_score <- recall_df$matched_genes/recall_df$total_curated_genes
View(recall_df)
ai_genes_with_collapsed_matches[ai_genes_with_collapsed_matches$PMID == "24533860",]
View(recall_df)
View(ai_genes_with_collapsed_matches)
# set anything greater than 1 to 1, it is because different gene notaitons for multiple
# species were matched
# Calculate recall score
recall_df <- recall_df %>%
mutate(
recall_score = matched_genes / total_curated_genes,
recall_score = pmin(recall_score, 1)  # Cap the recall score at 1
)
View(recall_df)
mean(recall_df$recall_score)
mean(recall_df$recall_score)
median(recall_df$recall_score)
average(recall_df$recall_score)
mode(recall_df$recall_score)
# set anything greater than 1 to 1, it is because different gene notaitons for multiple
# species were matched
# Calculate recall score
recall_df <- recall_df %>%
mutate(
recall_score_species_not_accounted_for = matched_genes / total_curated_genes,
recall_score_species_not_accounted_for = pmin(recall_score, 1)  # Cap the recall score at 1
)
View(recall_curated_data)
View(recall_df)
ai_genes_with_collapsed_matches$ai_species_standardised <- sapply(ai_genes_with_collapsed_matches$ai_species, standardise_species_name)
ai_genes_with_collapsed_matches$curator_species_standardised <- sapply(ai_genes_with_collapsed_matches$curator_species, standardise_species_name)
View(ai_genes_with_collapsed_matches)
ai_genes_with_collapsed_matches_filtered_for_species_match <- ai_genes_with_collapsed_matches[ai_genes_with_collapsed_matches$ai_species_standardised == ai_genes_with_collapsed_matches$curator_species_standardised, ]
View(ai_genes_with_collapsed_matches_filtered_for_species_match)
# Step 2: Count AI-matched genes per PMID with matching species
ai_gene_match_count <- ai_genes_with_collapsed_matches_filtered_for_species_match %>%
group_by(PMID) %>%
summarize(matched_genes = n_distinct(ai_symbol), .groups = "drop")
# Step 3: Join and calculate recall
recall_df_with_species_accounted_for <- curated_gene_count %>%
left_join(ai_gene_match_count, by = "PMID") %>%
mutate(
matched_genes = ifelse(is.na(matched_genes), 0, matched_genes), # Handle PMIDs with no matches
)
# set anything greater than 1 to 1, it is because different gene notaitons for multiple
# species were matched
# Calculate recall score
recall_df_with_species_accounted_for <- recall_df_with_species_accounted_for %>%
mutate(
recall_score_species_accounted_for = matched_genes / total_curated_genes#,
# recall_score_species_accounted_for = pmin(recall_score, 1)  # Cap the recall score at 1
)
View(recall_df_with_species_accounted_for)
# set anything greater than 1 to 1, it is because different gene notaitons for multiple
# species were matched
# Calculate recall score
recall_df_with_species_accounted_for <- recall_df_with_species_accounted_for %>%
mutate(
recall_score_species_accounted_for = matched_genes / total_curated_genes,
recall_score_species_accounted_for = pmin(recall_score, 1)  # Cap the recall score at 1
)
# set anything greater than 1 to 1, it is because different gene notaitons for multiple
# species were matched
# Calculate recall score
recall_df_with_species_accounted_for <- recall_df_with_species_accounted_for %>%
mutate(
recall_score_species_accounted_for = matched_genes / total_curated_genes,
recall_score_species_accounted_for = pmin(recall_score_species_accounted_for, 1)  # Cap the recall score at 1
)
View(recall_df_with_species_accounted_for)
mean(recall_df_with_species_accounted_for$recall_score_species_accounted_for)
mean(recall_df$recall_score_species_not_accounted_for)
# read in extracted data for each pmid in extended set
pmid_data <- read.csv("../output/pahogen_training_set_pmids_data_exploration/full_pathogen_set_pmid_data.csv")
# tidy publication date
pmid_data$Publication.Date <- pmid_data$Publication.Date
pmid_data$publication_year <- sub(".*'Year': '([0-9]{4}).*",
"\\1",
pmid_data$Publication.Date) %>% as.numeric()
library(tidyverse)
# read in extracted data for each pmid in extended set
pmid_data <- read.csv("../output/pahogen_training_set_pmids_data_exploration/full_pathogen_set_pmid_data.csv")
# tidy publication date
pmid_data$Publication.Date <- pmid_data$Publication.Date
pmid_data$publication_year <- sub(".*'Year': '([0-9]{4}).*",
"\\1",
pmid_data$Publication.Date) %>% as.numeric()
# read in full list of pmids that were sent for processing
all_pmids <- readLines("../output/pahogen_training_set_pmids_data_exploration/pathogen_training_set_pmids.txt")
# read in full list of pmids that didn't fail
pmids_with_outputs <- read.csv("../output/pahogen_training_set_pmids_data_exploration/pathogens_single_genes_prompt_complete_outputs.csv")
View(pmids_with_outputs)
pmids_with_outputs <- pmids_with_outputs$PMID %>% unique()
# Load required libraries
library(jsonlite)
library(ggplot2)
library(dplyr)
library(stringr)
library(tidyverse)
# Define the folder containing the JSON files
pmid_status_folder <- "C:/Users/jtzve/Desktop/llm-testbed_JT/caches/status"
# Get a list of all JSON files in the folder
json_files <- list.files(pmid_status_folder, pattern = "\\.json$", full.names = TRUE)
# Initialise an empty df to store the results
results_df <- data.frame(
PMID = character(),
species_latin_name = character(),
gene_ID = character(),
gene_name = character(),
gene_symbol = character(),
stringsAsFactors = FALSE
)
# Loop through each JSON file
for (json_file in json_files) {
# json_file_test_error <- "C:/Users/jtzve/Desktop/llm-testbed_JT/caches/status/19497128.json"
# Extract the PMID from the filename (remove folder path and .json extension)
pmid <- sub("\\.json$", "", basename(json_file))
# print(pmid)
# Read the JSON file
json_data <- fromJSON(json_file, flatten = TRUE)
# Check if "getPaperGenes" exists and succeeded
if (!is.null(json_data$getPaperGenes) && json_data$getPaperGenes$success) {
# Extract species and genes information
species_df <- json_data$getPaperGenes$response$species
# for each species
for (i in 1:nrow(species_df)) {
# print(i)
# i <- 4
# get the name of the species
species_name <- species_df$name[i]
# and the associated gene information
genes_df <- species_df$genes[[i]]
# check if any genes assigned to species, if not add the species
# and assigne all gene IDs to "no genes"
if (is.null(genes_df) || nrow(genes_df) == 0) {
results_df <- rbind(
results_df,
data.frame(
PMID = pmid,
species_latin_name = species_name,
gene_ID = "no genes",
gene_name = "no genes",
gene_symbol = "no genes",
stringsAsFactors = FALSE
)
)
} else {
# if yes, add the gene-species pairs to the results
# for each gene
for (j in 1:nrow(genes_df)) {
# extract the relevant identifiers and append to the df
results_df <- rbind(
results_df,
data.frame(
PMID = pmid,
species_latin_name = species_name,
gene_ID = genes_df$identifier[j],
gene_name = genes_df$name[j],
gene_symbol = genes_df$symbol[j],
stringsAsFactors = FALSE
)
)
}
}
}
}
}
View(results_df)
successful_pmids <- results_df$PMID %>% unique()
write.table(successful_pmids, file =  "../output/pahogen_training_set_pmids_data_exploration/successful_pmids.txt")
write.table(successful_pmids,
file =  "../output/pahogen_training_set_pmids_data_exploration/successful_pmids.txt",
row.names = FALSE)
writeLines(successful_pmids,
file =  "../output/pahogen_training_set_pmids_data_exploration/successful_pmids.txt")
write_linesnes(successful_pmids,
file =  "../output/pahogen_training_set_pmids_data_exploration/successful_pmids.txt")
write_lines(successful_pmids,
file =  "../output/pahogen_training_set_pmids_data_exploration/successful_pmids.txt")
library(tidyverse)
# read in extracted data for each pmid in extended set
pmid_data <- read.csv("../output/pahogen_training_set_pmids_data_exploration/full_pathogen_set_pmid_data.csv")
# tidy publication date
pmid_data$Publication.Date <- pmid_data$Publication.Date
pmid_data$publication_year <- sub(".*'Year': '([0-9]{4}).*",
"\\1",
pmid_data$Publication.Date) %>% as.numeric()
# read in full list of pmids that were sent for processing
all_processed_pmids <- readLines("../output/pahogen_training_set_pmids_data_exploration/pathogen_training_set_pmids.txt")
# read in full list of pmids that didn't fail
successful_pmids <- readLines("../output/pahogen_training_set_pmids_data_exploration/successful_pmids.txt")
failed_pmids <- setdiff(all_processed_pmids, successful_pmids)
# read in full list of pmids that were sent for processing
all_processed_pmids <- readLines("../output/pahogen_training_set_pmids_data_exploration/pathogen_training_set_pmids.txt") %>% unique()
# if pmid in pmid_data is in the list of failed, mark it as such
pmid_data$failed <- pmid_data$PMID %in% failed_pmids
# Get the top 10 journals by count
top_journals <- pmid_data %>%
count(Journal) %>%
top_n(10, wt = n) %>%
pull(Journal)
# Filter data to include only top journals
filtered_data <- pmid_data %>%
filter(Journal %in% top_journals)
# Plot the relationship between Journal and Failure Status
ggplot(filtered_data, aes(x = Journal, fill = failed)) +
geom_bar(position = "dodge") +
labs(title = "Failure Status by Journal",
x = "Journal",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plot the distribution of publication years by failure status
ggplot(pmid_data, aes(x = as.factor(failed), y = publication_year, fill = as.factor(failed))) +
geom_violin(alpha = 0.6) +
geom_boxplot(width = 0.2, color = "black", alpha = 0.4) +  # Adjusted width for better overlay
labs(title = "Publication Year vs. Failure Status",
x = "Failed",
y = "Publication Year") +
scale_y_continuous(breaks = seq(min(pmid_data$publication_year, na.rm = TRUE),
max(pmid_data$publication_year, na.rm = TRUE), by = 5)) +
theme_minimal() +
theme(legend.position = "none")  # Hide legend if failed status is self-evident
# Convert Free.Text.Availability and failed to factors
pmid_data$Free.Text.Availability <- as.factor(pmid_data$Free.Text.Availability)
pmid_data$failed <- as.factor(pmid_data$failed)
# Plot the relationship between Free Text Availability and Failure Status
ggplot(pmid_data, aes(x = Free.Text.Availability, fill = failed)) +
geom_bar(position = "dodge") +
labs(title = "Free Text Availability vs. Failure Status",
x = "Free Text Availability",
y = "Count") +
theme_minimal()
# Plot the relationship between Journal and Failure Status
library(dplyr)
# Summarize to find journals with only failed or only non-failed articles
journal_status_summary <- pmid_data %>%
group_by(Journal) %>%
summarize(all_failed = all(failed == TRUE),
all_non_failed = all(failed == FALSE),
total_articles = n())
# Filter for journals that are either only failed or only non-failed
only_failed_journals <- journal_status_summary %>% filter(all_failed == TRUE)
only_non_failed_journals <- journal_status_summary %>% filter(all_non_failed == TRUE)
print("Journals with only failed articles:")
print(only_failed_journals)
print("Journals with only non-failed articles:")
print(only_non_failed_journals)
table(pmid_data$Journal)
library(ggplot2)
# Plot the count of failed vs non-failed articles for each journal
ggplot(pmid_data, aes(x = Journal, fill = as.factor(failed))) +
geom_bar() +
labs(title = "Failure Status by Journal",
x = "Journal",
y = "Count of Articles",
fill = "Failed") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "blue"))
# Plot the count of failed vs non-failed articles for each journal
ggplot(pmid_data, aes(x = Journal, fill = as.factor(failed))) +
geom_bar() +
labs(title = "Failure Status by Journal",
x = "Journal",
y = "Count of Articles",
fill = "Failed") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_fill_manual(values = c("TRUE" = "salmon", "FALSE" = "dodgerblue"))
library(dplyr)
# Ensure `failed` is logical (TRUE/FALSE) or convert it to numeric
filtered_data <- pmid_data %>%
filter(publication_year > 2008) %>%
mutate(failed = as.numeric(as.logical(failed)))
# Group by Journal and calculate counts
journal_summary <- filtered_data %>%
group_by(Journal) %>%
summarize(
total_articles = n(),
failed_count = sum(failed),
non_failed_count = total_articles - failed_count
) %>%
# Filter for journals with more than 5 articles
filter(total_articles > 5)
# Identify journals with only failed or only non-failed publications
only_failed_journals <- journal_summary %>% filter(failed_count == total_articles)
only_non_failed_journals <- journal_summary %>% filter(non_failed_count == total_articles)
# Display results
print("Journals with only failed publications:")
print(only_failed_journals)
print("Journals with only non-failed publications:")
print(only_non_failed_journals)
library(dplyr)
library(ggplot2)
# Calculate the percentage of failed and successful publications by journal
journal_summary <- filtered_data %>%
group_by(Journal) %>%
summarize(
total_articles = n(),
failed_count = sum(failed),
success_count = total_articles - failed_count,
failed_percent = (failed_count / total_articles) * 100,
success_percent = (success_count / total_articles) * 100
) %>%
# Filter for journals with more than 5 articles
filter(total_articles > 5)
# Reshape data for plotting
plot_data <- journal_summary %>%
select(Journal, failed_percent, success_percent) %>%
pivot_longer(cols = c(failed_percent, success_percent),
names_to = "status",
values_to = "percentage") %>%
mutate(percentage = ifelse(status == "failed_percent", -percentage, percentage),
status = ifelse(status == "failed_percent", "Failed", "Successful"))
# Plot
# Reshape data for plotting
plot_data <- journal_summary %>%
select(Journal, failed_count, success_count, failed_percent, success_percent) %>%
pivot_longer(cols = c(failed_count, success_count, failed_percent, success_percent),
names_to = c("status", ".value"),
names_pattern = "(failed|success)_(.*)") %>%
mutate(status = ifelse(status == "failed", "Failed", "Successful"))
# Plot
ggplot(plot_data, aes(x = reorder(Journal, percent), y = status, size = count, fill = status)) +
geom_point(shape = 21, alpha = 0.7) +
geom_text(aes(label = count), color = "white", fontface = "bold", size = 3) +
coord_flip() +
scale_size(range = c(5, 20)) +  # Adjust bubble size range
labs(title = "Percentage of Failed vs. Successful Publications by Journal",
x = "Journal",
y = "Publication Status",
size = "Count",
fill = "Publication Status") +
scale_fill_manual(values = c("Failed" = "blue", "Successful" = "orange")) +
theme_minimal()
# Calculate the percentage of failed and successful publications by journal
journal_summary <- filtered_data %>%
group_by(Journal) %>%
summarize(
total_articles = n(),
failed_count = sum(failed),
success_count = total_articles - failed_count,
failed_percent = (failed_count / total_articles) * 100,
success_percent = (success_count / total_articles) * 100
) %>%
# Filter for journals with more than 5 articles
filter(total_articles > 5)
# Reshape data for plotting
plot_data <- journal_summary %>%
select(Journal, failed_percent, success_percent, total_articles) %>%
pivot_longer(cols = c(failed_percent, success_percent),
names_to = "status",
values_to = "percentage") %>%
mutate(percentage = ifelse(status == "failed_percent", -percentage, percentage),
status = ifelse(status == "failed_percent", "Failed", "Successful"))
# Plot with total articles as text
ggplot(plot_data, aes(x = reorder(Journal, -percentage), y = percentage)) +
geom_bar(aes(fill = status), stat = "identity", position = "identity") +
geom_text(data = journal_summary, aes(x = Journal, y = 0, label = total_articles),
vjust = -1, size = 3.5, color = "black") +
scale_y_continuous(labels = abs) +  # Display y-axis labels as positive values
labs(title = "Percentage of Failed vs. Successful Publications after 2008 by Journal",
x = "Journal",
y = "Percentage",
fill = "Publication Status") +
scale_fill_manual(values = c("Failed" = "blue", "Successful" = "orange")) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
